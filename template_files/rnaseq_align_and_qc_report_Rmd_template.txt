For each sample, the following programs were run to generate the data necessary to create this report. Written as for unstranded paired-end data. For single-end reads, R2s and insert size metrics would be omitted. <br> 

> java -Xmx1024m TrimmomaticPE -phred33 [raw_sample_R1] [raw_sample_R2] [sample_R1] [sample_R1_unpaired] [sample_R2] [sample_R2_unpaired] HEADCROP:[bases to trim, if any] ILLUMINACLIP:[sample_primer_fasta]:2:30:10 MINLEN:50<br> <br>
> fastqc [sample_R1] [sample_R2] <br> <br>
> cat [sample_R1/R2] | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(count[read]==1){unique++}};print total,unique,unique*100/total}' <br>


The following STAR options were used: <br>

> STAR --genomeDir [ref_genome_index] --runThreadN 12 --outReadsUnmapped Fastx --outMultimapperOrder Random --outSAMmultNmax 1 --outFilterIntronMotifs RemoveNoncanonical --outSAMstrandField intronMotif --outSAMtype BAM SortedByCoordinate --readFilesIn [sample_R1] [sample_R2] <br>


Using aligned output files accepted_hits.bam and unmapped.bam:<br>

> samtools sort accepted_hits.bam accepted_hits.sorted <br><br>
> samtools index accepted_hits.sorted.bam <br><br>
> samtools idxstats accepted_hits.sorted.bam > accepted_hits.sorted.stats <br><br>
> bamtools stats -in accepted_hits.sorted.bam > accepted_hits.sorted.bamstats <br><br>
> bamtools filter -in accepted_hits.sorted.bam -script cigarN.script | bamtools count <br><br>
> samtools view -c unmapped.bam <br><br>
> java -Xmx2g -jar CollectRnaSeqMetrics.jar REF_FLAT=[ref_flat file] STRAND_SPECIFICITY=NONE INPUT=accepted_hits.bam OUTPUT=RNASeqMetrics <br><br>
> java -Xmx2g -jar CollectInsertSizeMetrics.jar HISTOGRAM_FILE=InsertSizeHist.pdf INPUT=accepted_hits.sorted.bam OUTPUT=InsertSizeMetrics <br>


```{r, eval=T, echo=F, message=F}
metrics.data <- read.table(paste(project_name,"_rnaseqmetrics_hist.txt", sep=""), header=T)
counts.data <- read.table(paste(project_name,"_counts.txt", sep=""), header=T, sep="\t")
#ercc.data <- read.table(paste(project_name,"_ERCC.txt", sep=""), header=T, as.is=T)
summary.data <- read.table(paste(project_name,"_rnaseqmetrics_summary.txt", sep=""), header=T, as.is=T, sep="\t")
bamstats.data <- read.table(paste(project_name,"_bamstats_counts.txt", sep=""), header=T, as.is=T, sep="\t")
if (library.type %in% c("PE")) {
	insert.summary.data <- read.table(paste(project_name,"_insertmetrics_summary.txt", sep=""), header=T, as.is=T, sep="\t")
	insert.metrics.data <- data.frame(c(0:1))
	names(insert.metrics.data) <- "Insert_Size"
	for (i in c(1:length(sample.names))){
		curr.hist.data <- read.table(paste(project_name,"_",sample.names[i],"_insertmetrics_hist.txt", sep=""), header=T, as.is=T, sep="\t")
		insert.metrics.data <- merge(insert.metrics.data, curr.hist.data, all=TRUE)
		}
	}
unique.counts.data <- read.table(paste(project_name,"_unique_counts.txt", sep=""), header=T, sep="\t")
duplicates <- read.table(paste(project_name,"_duplicates.txt", sep=""), header=T, sep="\t", as.is=T)
```


```{r lib, echo=F, message=F, warnings=F}
#library(xtable)
library(pander)
#library(knitr)
library(RColorBrewer)
library(DT)
library(ggplot2)
library(reshape2)
```

## Summary Read Numbers 

The number of raw reads correspond to those that passed Casava QC filters, were trimmed to remove adaptors by Trimmomatic, and were aligned by STAR to ref_genome+ERCC transcripts as reported in .info files. Unique read counts were obtained by using awk on trimmed fastq files. FastQC estimates of percentage of sequences remaining after deduplication were retrieved from fastqc_data.txt files. Bamtools statistics were based on sorted and indexed bam files. The mapped reads were those that mapped to reference and were output by STAR to accepted_hits.bam. The unmapped reads were output by STAR to unmapped.bam. Some reads may be mapped to multiple locations in the genome so that the number of total reads reported by bamstats may be greater than the number of raw reads. The Junction spanning reads are computed based on accepted_hits.bam CIGAR entries containing "N." Related text files that were saved:


```{r, eval=T, echo=F, message=FALSE, results='asis'}
cat(project_name, "_read_counts.txt\n\n", project_name, "_duplicates.txt\n\n", project_name, "_unique_counts.txt\n\n", project_name, "_bamstats_counts.txt\n\n")
```

### Total Number of Raw Reads Summary

```{r, eval=T, echo=F, message=FALSE}
if (library.type %in% c("PE")) {
	R1_dups = duplicates[1, seq(2, length(duplicates[1, ]), 2)]
	unique.counts.data.2 <- cbind(unique.counts.data, t(R1_dups))
	R2_dups = duplicates[1, seq(3, length(duplicates[1, ]), 2)] 
	unique.counts.data.2 <- cbind(unique.counts.data.2, t(R2_dups))
	row.names(unique.counts.data.2) <- c(1:length(row.names(unique.counts.data.2)))
	names(unique.counts.data.2)[c(8:9)] <- c("Fastqc_Total_Deduplicated_Percentage_R1", "Fastqc_Total_Deduplicated_Percentage_R2")
	unique.counts.data.2$R1_Percent_Unique <- round(unique.counts.data.2$R1_Percent_Unique, 2) #else get a ton of decimal points
	unique.counts.data.2$R2_Percent_Unique <- round(unique.counts.data.2$R2_Percent_Unique, 2) #else get a ton of decimal points
	unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R1 <- round(unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R1, 2)
	unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R2 <- round(unique.counts.data.2$Fastqc_Total_Deduplicated_Percentage_R2, 2)
	} else {
	unique.counts.data.2 <- cbind(unique.counts.data, t(duplicates[1, c(2:length(duplicates[1, ]))]))
	row.names(unique.counts.data.2) <- c(1:length(row.names(unique.counts.data.2)))
	names(unique.counts.data.2)[5] <- "Fastqc_Total_Duplicate_Estimate"
	unique.counts.data.2$Percent_Unique <- round(unique.counts.data.2$Percent_Unique, 2) #else get a ton of decimal points
	unique.counts.data.2$Fastqc_Total_Duplicate_Estimate <- round(unique.counts.data.2$Fastqc_Total_Duplicate_Estimate, 2)
	}
DT::datatable(unique.counts.data.2, rownames = FALSE, options = list(pageLength = 25))
```

### Plot: Percentage of Unique Reads in Original Fastq File

```{r, eval=T, echo=F, message=FALSE, warning=FALSE, fig.width=13, fig.height=10}
par(mai=c(1.02,1,0.82,2.5))
if (library.type %in% c("PE")) {
	unique.counts.only <- unique.counts.data[,c("Sample","R1_Percent_Unique","R2_Percent_Unique")]	
	#if sample names start with a number, append "x" to names - else get an error.
	if (substring(unique.counts.only$Sample[1], 1, 1) %in% c("0","1","2","3","4","5","6","7","8","9")) { # only need to test one sample name
		unique.counts.only$Sample <- paste0("x",unique.counts.only$Sample)
	}
	unique.counts.only <- melt(unique.counts.only)
	#barplot(unique.counts.only, beside=TRUE, ylim=c(0,100), col=c("red", "darkblue"), border=NA, main=project_name, xlab="Sample", ylab="Percentage of Unique Reads in Original Fastq File", names.arg=c(1:length(unique.counts.data$Sample)), cex.axis=1.75, cex.lab=2, cex.main=2)
	#legend("right", c("R1", "R2"), fill=c("red", "darkblue"), border=NA, bty="n", xpd=TRUE, inset=-0.3, cex=1.5)
	ggplot(unique.counts.only, aes(x=Sample, y=value, fill=variable))+ 
		geom_bar(stat="identity", position="dodge") +
		scale_fill_manual(values=c("navy", "firebrick")) +
		labs(title=project_name, x="Sample", y="Percentage of Unique Reads in Original Fastq File") +
		ylim(0, 100) +
		theme_bw() +
		theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		legend.title = element_text(color="white", size=12),
		legend.text = element_text(size = 16),
            	axis.text.y = element_text(size=14),
            	plot.title = element_text(size=18, hjust=0.5, face="bold"),
            	axis.title.x = element_text(size=14),
            	axis.title.y = element_text(size=16))
	} else {
	#barplot(unique.counts.data$Percent_Unique, ylim=c(0,100), col=c("red"), border=NA, main=project_name, xlab="Sample", ylab="Percentage of Unique Reads in Original Fastq File", names.arg=c(1:length(unique.counts.data$Sample)), cex.axis=1.75, cex.lab=2, cex.main=2)	
	ggplot(data = unique.counts.data, aes(x = Sample, y = Percent_Unique)) + 
		geom_bar(stat="identity", fill="firebrick") +
		labs(title=project_name, x="Sample", y="Percentage of Unique Reads in Original Fastq File") +
		ylim(0, 100) +
		theme_bw() +
		theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
            	axis.text.y = element_text(size=14),
            	plot.title = element_text(size=18, hjust=0.5, face="bold"),
            	axis.title.x = element_text(size=14),
            	axis.title.y = element_text(size=16))
}
```

### Plot: Sequence Duplication Level

```{r, eval=T, echo=F, message=FALSE, fig.width=12, fig.height=10}
color.list <- rep(brewer.pal(12,"Paired"), length(sample.names))
par(mai=c(1.02,1,0.82,3)) #bottom, left, top, and right
if (library.type %in% c("PE")) {
	for (i in seq(1, 2*length(sample.names), 2)){
		  sample.index <- i+1
		  if (i==1) {
			 plot(duplicates[-1, sample.index], col=color.list[i], type="o", xlab="Sequence Duplication Level", ylab="Percentage of Total Sequences", main=project_name, ylim=c(0, max(c(100, ceiling(max(duplicates[11, -1]))))), cex.axis=1.75, cex.lab=2, cex.main=2)
			 lines(duplicates[-1, sample.index+1], col=color.list[i], type="o")
		  } else {
			 lines(duplicates[-1, sample.index], col=color.list[i], type="o")
			 lines(duplicates[-1, sample.index+1], col=color.list[i], type="o")
		  }
	}
	legend("topright", sample.names, fill=color.list[seq(1, 2*length(sample.names), 2)], bty="n", border=color.list[seq(1, 2*length(sample.names), 2)], cex=1.1, xpd=TRUE, ncol=2, inset=c(0.05,0))
	} else {
	for (i in seq(1, length(sample.names))){
		  sample.index <- i+1
		  if (i==1) {
			 plot(duplicates[-1, sample.index], col=color.list[i], type="o", xlab="Sequence Duplication Level", ylab="Relative Scale Where Single Reads Have Value 100", main=project_name, ylim=c(0, max(c(100, ceiling(max(duplicates[11, -1]))))), cex.axis=1.75, cex.lab=2, cex.main=2)
		  } else {
			 lines(duplicates[-1, sample.index], col=color.list[i], type="o")
		  }
	legend("topright", sample.names, fill=color.list, bty="n", border=color.list, cex=1.1, xpd=TRUE, ncol=2, inset=c(0.05,0))
	}
}
```

```{r, eval=T, echo=F, message=FALSE}
#Total Number of Reads Summary 
if (aligner == "tophat") {
	total.read.data <- read.table(paste(project_name,"_read_counts.txt", sep=""), header=T, sep="\t")
	if (library.type %in% c("PE")) {
		total.read.data$Total_Raw_Reads <- total.read.data$R1_Raw_Reads + total.read.data$R2_Raw_Reads
		total.read.data$Total_Aligned_Reads <- total.read.data$R1_Aligned_Reads + total.read.data$R2_Aligned_Reads
		total.read.data$Pct_Aligned_Reads <- 100*total.read.data$Total_Aligned_Reads/total.read.data$Total_Raw_Reads
		DT::datatable(total.read.data, options = list(pageLength = 25))
		} else {
		total.read.data$Pct_Aligned_Reads <- 100*total.read.data$Aligned_Reads/total.read.data$Raw_Reads
		DT::datatable(total.read.data, options = list(pageLength = 25))
		}
	}
```

### Bamtools Reads Summary

```{r, eval=T, echo=F, message=FALSE}
if (library.type %in% c("PE")) {
	if (aligner == "tophat") {
		bamstats.summary <- bamstats.data[c(2:4, 7:14), c(2:length(names(bamstats.data))), drop=FALSE]
		bamstats.summary <- rbind(bamstats.summary, apply(bamstats.data[c(2,14),-1, drop=FALSE], 2, sum))
		row.names(bamstats.summary) <- c(bamstats.data[c(2:4, 7:14), 1], "Total Reads")
	} else {
		bamstats.summary <- bamstats.data[c(2:4, 7:13), c(2:length(names(bamstats.data))), drop=FALSE]
		total_reads_per_sample <- 2*unique.counts.data$R1_Raw_Reads
		bamstats.summary <- rbind(bamstats.summary, total_reads_per_sample-bamstats.summary[1, ] )
		bamstats.summary <- rbind(bamstats.summary, total_reads_per_sample)
		row.names(bamstats.summary) <- c(bamstats.data[c(2:4, 7:13), 1], "Unmapped Reads", "Total Reads")
	}
} else {
	if (aligner == "tophat") {
		bamstats.summary <- bamstats.data[c(2:4, 8:9), c(2:length(names(bamstats.data))), drop=FALSE]
		bamstats.summary <- rbind(bamstats.summary, apply(bamstats.data[c(2,9),-1, drop=FALSE], 2, sum))
		row.names(bamstats.summary) <- c(bamstats.data[c(2:4
, 8:9), 1], "Total Reads")
	} else {
		bamstats.summary <- bamstats.data[c(2:4, 8), c(2:length(names(bamstats.data))), drop=FALSE]
		total_reads_per_sample <- 2*unique.counts.data$Raw_Reads
		bamstats.summary <- rbind(bamstats.summary, total_reads_per_sample-bamstats.summary[1, ] )
		bamstats.summary <- rbind(bamstats.summary, total_reads_per_sample)
		row.names(bamstats.summary) <- c(bamstats.data[c(2:4, 8), 1], "Unmapped Reads", "Total Reads")
	} 
}
DT::datatable(bamstats.summary, options = list(pageLength = 25))
```


### Bamtools Reads Summary As Percentage of Mapped Reads

```{r, eval=T, echo=F, message=FALSE}
#if use xtable: print(xtable(bamstats.percent.table, split.table = Inf), type = 'html')
#need results="asis" for xtable to be output as table--else will be output as html code

if (library.type %in% c("PE")) {
	bamstats.percent.table <- 100*bamstats.summary[c(1:10), , drop=FALSE] / rep(as.numeric(bamstats.summary[1, ]), each=10)
	} else {
	bamstats.percent.table <- 100*bamstats.summary[c(1:4), , drop=FALSE] / rep(as.numeric(bamstats.summary[1, ]), each=4)
	}
bamstats.percent.table <- round(bamstats.percent.table, 2)	
DT::datatable(bamstats.percent.table, options = list(pageLength = 25))
```

### Percentage of Mapped/Unmapped Reads

```{r, eval=T, echo=F, message=FALSE}
if (library.type %in% c("PE")) {
	mapped.percent.table <- 100*bamstats.summary[c(1,11), , drop=FALSE] / rep(as.numeric(bamstats.summary[12, ]), each=2)
	} else {
	mapped.percent.table <- 100*bamstats.summary[c(1,5), , drop=FALSE] / rep(as.numeric(bamstats.summary[6, ]), each=2)
	}
mapped.percent.table <- round(mapped.percent.table, 2)
DT::datatable(mapped.percent.table, options = list(pageLength = 25))
```

### Plot: Percentage of Mapped/Unmapped Reads

```{r, eval=T, echo=F, message=FALSE, fig.width=9, fig.height=10}
par(mai=c(1.02,1,0.82,2.5))
#barplot(as.matrix(mapped.percent.table), beside=FALSE, ylim=c(0,100), col=c("red", "darkblue"), border=NA, main=project_name, xlab="Sample", ylab="Percentage of Total Reads", names.arg=c(1:length(names(mapped.percent.table))), cex.axis=1.75, cex.lab=2, cex.main=2)
#legend("right", c("Mapped", "Unmapped"), fill=c("red", "darkblue"), border=NA, bty="n", xpd=TRUE, inset=-0.3, cex=1.5)

rownames(mapped.percent.table) <- c("Mapped", "Unmapped")
mapped.percent.table$which  <- rownames(mapped.percent.table)
mapped.percent.for.plot <- melt(mapped.percent.table, id.vars="which")
mapped.percent.for.plot$which <- factor(mapped.percent.for.plot$which, levels=c("Unmapped", "Mapped")) # order so mapped reads are at the bottom 

#note stacked is default for ggplot2
ggplot(data = mapped.percent.for.plot, aes(x = variable, y = value, fill=which)) + 
	geom_bar(stat="identity") +
	scale_fill_manual(values=c("navy", "firebrick")) +
	labs(title=project_name, x="Sample", y="Percentage of Total Reads") +
	ylim(0, 100) +
	theme_bw() +
	theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		legend.title = element_text(color="white", size=12),
		legend.text = element_text(size = 16),
           	axis.text.y = element_text(size=16),
         	plot.title = element_text(size=18, hjust = 0.5, face="bold"),
           	axis.title.x = element_text(size=18),
         	axis.title.y = element_text(size=18))
```

### Plot: Percentage of Junction Spanning Reads Among Mapped Reads

```{r, eval=T, echo=F, message=FALSE, fig.width=8, fig.height=10}
par(mai=c(1.02,1,0.82,0.42))
#barplot(as.matrix(bamstats.percent.table[length(row.names(bamstats.percent.table)), , drop=FALSE]), ylim=c(0, ceiling(max(bamstats.percent.table[length(row.names(bamstats.percent.table)), ]))), col=c("red"), border=NA, main=project_name, xlab="Sample", ylab="Percentage of Junction Spanning Reads Among Mapped Reads", names.arg=c(1:length(names(bamstats.percent.table))), cex.axis=1.75, cex.lab=2, cex.main=2)

junc.for.table <- melt(bamstats.percent.table["Junction Spanning Reads",])

ggplot(data = junc.for.table, aes(x = variable, y = value)) + 
	geom_bar(stat="identity", fill="firebrick") +
	labs(title=project_name, x="Sample", y="Percentage of Junction Spanning Reads Among Mapped Reads") +
	ylim(0, ceiling(max(bamstats.percent.table[length(row.names(bamstats.percent.table)), ]))) +
	theme_bw() +
	theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		legend.title = element_text(color="white", size=12),
		legend.text = element_text(size = 16),
           	axis.text.y = element_text(size=16),
         	plot.title = element_text(size=18, hjust = 0.5, face="bold"),
           	axis.title.x = element_text(size=18),
         	axis.title.y = element_text(size=18))
```


## RnaSeqMetrics Summary

The Picard Tools RnaSeqMetrics function computes the number of bases assigned to various classes of RNA. It also computes the coverage of bases across all transcripts (normalized to a same-sized reference). Computations are based on comparison to a refFlat file. Related text files that were saved:

```{r, eval=T, echo=F, message=FALSE, results='asis'}
cat(project_name, "_rnaseqmetrics_summary.txt\n\n", project_name, "_rnaseqmetrics_hist.txt\n\n")
```


### Reference Genome Mapped Reads Summary

```{r, eval=T, echo=F, message=FALSE}
sum.data <- summary.data[c(1:2,4:10,12:22), c(2:length(names(summary.data))), drop=FALSE]
row.names(sum.data) <- summary.data[c(1:2,4:10,12:22), 1]
table.digits <- matrix(c(rep(0,9),rep(3,11)), nrow=20, ncol=length(names(summary.data)))
sum.data["PCT_CODING_BASES",] <- round(sum.data["PCT_CODING_BASES",]*100, 2)
sum.data["PCT_UTR_BASES",] <- round(sum.data["PCT_UTR_BASES",]*100, 2)
sum.data["PCT_INTRONIC_BASES",] <- round(sum.data["PCT_INTRONIC_BASES",]*100, 2)
sum.data["PCT_INTERGENIC_BASES",] <- round(sum.data["PCT_INTERGENIC_BASES",]*100, 2)
sum.data["PCT_MRNA_BASES",] <- round(sum.data["PCT_MRNA_BASES",]*100, 2)
sum.data["PCT_USABLE_BASES",] <- round(sum.data["PCT_USABLE_BASES",]*100, 2)
sum.data["PCT_CORRECT_STRAND_READS",] <- round(sum.data["PCT_CORRECT_STRAND_READS",]*100, 2)
DT::datatable(sum.data, options = list(pageLength = 25))
```

### Plot: Percentages of Total Mapped Bases Mapping to mRNA, Intronic and Intergenic Regions

```{r, eval=T, echo=F, message=FALSE, fig.width=10, fig.height=10}
par(mai=c(1.02,1,0.82,2.5))
#barplot(sapply(sum.data[c(14,12,13), ], as.numeric)*100, beside=TRUE, ylim=c(0,100), col=c("red", "darkblue", "darkgreen"), border=NA, main=project_name, xlab="Sample", ylab="Percentage of Total Mapped Bases", names.arg=c(1:length(names(sum.data))), cex.axis=1.75, cex.lab=2, cex.main=2)
#legend("right", c("mRNA", "Intronic", "Intergenic"), fill=c("red", "darkblue", "darkgreen"), border=NA, bty="n", xpd=TRUE, inset=-0.17, cex=1.5)

sum.data.for.plot <- sum.data[c("PCT_INTERGENIC_BASES", "PCT_INTRONIC_BASES", "PCT_MRNA_BASES"),]
rownames(sum.data.for.plot) <- c("Intergenic", "Intronic", "mRNA")
sum.data.for.plot$which  <- rownames(sum.data.for.plot)
sum.data.melted <- melt(sum.data.for.plot, id.vars="which")
sum.data.melted$which <- factor(sum.data.melted$which, levels=c("mRNA", "Intronic", "Intergenic")) # desired order

ggplot(data = sum.data.melted, aes(x = variable, y = value, fill=which)) + 
	geom_bar(stat="identity", position = "dodge") +  #note stacked is default for ggplot2, so must specify "dodge" to get side-by-side bars
	scale_fill_manual(values=c("red", "darkblue", "darkgreen")) +
	labs(title=project_name, x="Sample", y="Percentage of Total Mapped Bases") +
	ylim(0, 100) +
	theme_bw() +
	theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
		legend.title = element_text(color="white", size=12),
		legend.text = element_text(size = 16),
           	axis.text.y = element_text(size=16),
         	plot.title = element_text(size=20, hjust = 0.5, face="bold"),
           	axis.title.x = element_text(size=18),
         	axis.title.y = element_text(size=18))
```

### Plot: Normalized Coverage

```{r, eval=T, echo=F, message=FALSE, fig.width=14, fig.height=10}
delta <- 1/(2*length(sample.names))
c <- rep(brewer.pal(12,"Paired"), length(sample.names))

par(lwd=20*delta,mai=c(1.02,1,0.82,5))
sample.names <- names(metrics.data)[2:length(names(metrics.data))]
y.max <- max(metrics.data[ ,c(2:(length(sample.names)+1)), drop=FALSE])
for (i in c(1:length(sample.names))){
	  sample.index <- i+1
	  if (i==1) {
		 plot(metrics.data[ ,1], metrics.data[,sample.index], type="l", col=c[i], xlab="Normalized Position", ylab="Normalized Coverage", main=project_name, bty='L', ylim=c(0,y.max), cex.axis=1.75, cex.lab=2, cex.main=2)
	  } else {
		 shifted = metrics.data[,1]+delta*(i-1)
		 lines(shifted, metrics.data[,sample.index], col=c[i])
	  }
}
legend("right", sample.names, fill=c, bty="n", border=c, cex=1.1, xpd=TRUE, inset=-0.46)
```

```{r setup, echo=FALSE}
library(knitr)
stranded <- if (library.type %in% c("PE")) {TRUE} else {FALSE}   #use this to replace all the if conditions in subsequent code chunks
```

```{r, eval = stranded, echo=FALSE}
asis_output("## InsertSizeMetrics Summary<br>") 
```

```{r, eval = stranded, echo=FALSE}
asis_output("For paired-end data, the Picard Tools CollectInsertSizeMetrics function was used to compute the distribution of insert sizes in the accepted_hits.bam file and create a histogram. Related text files that were saved: ")
```


```{r, eval=T, echo=F, message=FALSE, results='asis'}
if (library.type %in% c("PE")) {
	cat(project_name, "_insertmetrics_summary.txt\n\n")
	}
```

```{r, eval=T, echo=F, message=FALSE}
# Insert Size Summary
if (library.type %in% c("PE")) {
	insert.sum.data <- apply(insert.summary.data[c(1:7), c(2:length(names(insert.summary.data))), drop=FALSE], 2, as.numeric)
	row.names(insert.sum.data) <- insert.summary.data[c(1:7), 1]
	table.digits <- matrix(c(rep(0,4),rep(2,2),0), nrow=7, ncol=length(names(insert.summary.data)))
	DT::datatable(insert.sum.data, options = list(pageLength = 25))
	#pander::pandoc.table(insert.sum.data, split.table = Inf)
	}
```

```{r, eval=T, echo=F, message=FALSE, fig.width=12, fig.height=10}
if (library.type %in% c("PE")) {
	par(mai=c(1.02,1,0.82,0.42))
	barplot(insert.sum.data[1, , drop=FALSE], ylim=c(0, max(insert.sum.data[1, ])+100), col=c("red"), border=NA, main=project_name, xlab="Sample", ylab="Median Insert Size", names.arg=c(1:length(sample.names)), cex.axis=0.9)
	}
```

```{r, eval=T, echo=F, message=FALSE, fig.width=12, fig.height=10}
par(mai=c(1.02,1,0.82,2)) #bottom, left, top, and right
if (library.type %in% c("PE")) {
	delta <- 1/(2*length(sample.names))
	c <- rep(brewer.pal(12,"Paired"), length(sample.names))
	y.max <- max(insert.metrics.data[ ,-1, drop=FALSE], na.rm=TRUE)
	for (i in c(1:length(sample.names))){
		  sample.index <- i+1
		  if (i==1) {
			 plot(insert.metrics.data[ ,1], insert.metrics.data[ ,sample.index], type="l", col=c[i], xlab="Insert Size", ylab="Read Count", main=project_name, bty='L', ylim=c(0,y.max), xlim=c(0, 2000), cex.axis=1.75, cex.lab=2, cex.main=2)
		  } else {
			 shifted = insert.metrics.data[ ,1]+delta*(i-1)
			 lines(shifted, insert.metrics.data[ ,sample.index], col=c[i])
		  }
	}
	legend("right", sample.names, fill = c, bty="n", border=c, cex=1.1, ncol=2, inset=c(-0.05,0))


	}
```

## Reads per Chromosome

Samtools produces a summary document that includes the number of reads mapped to each chromosome. Related text files that were saved:
```{r, eval=T, echo=F, message=FALSE, results='asis'}
cat("\n\n", project_name, "_counts.txt\n\n")
```

```{r, eval=T, echo=F, message=FALSE}

sample.names <- names(counts.data)[3:length(names(counts.data))]
delta <- 1/(2*length(sample.names))
c <- rep(brewer.pal(12,"Paired"), length(sample.names))
if (genome=="hg19") {
	counts.data <- counts.data[order(counts.data[, 1]), , drop=FALSE]
	counts.data.chr.order <- order(as.numeric(levels(counts.data[1:22,1])[as.integer(counts.data[1:22,1])]))
	counts.data.ordered.by.chr <- counts.data[1:22, ][counts.data.chr.order, ]
	counts.data.ordered.by.chr <- rbind(counts.data.ordered.by.chr, counts.data[25:26, ], counts.data[23:24, ])
	#cat("For human, the hg19 assembly was used. We estimate the number of rRNA reads as those mapped to chrM plus chrUn_gl000220, corresponding to 12S, 16S and 5.8S rRNA. The 'Other' category contains all other chr*_random and chrUn_* available. If using the 2014 updated version of the hg19 files, these categories are no longer present.")
	} else if (genome=="hg38") {
	counts.data <- counts.data[order(counts.data[, 1]), , drop=FALSE]
	counts.data.chr.order <- order(as.numeric(levels(counts.data[1:22,1])[as.integer(counts.data[1:22,1])]))
	counts.data.ordered.by.chr <- counts.data[1:22, ][counts.data.chr.order, ]
	counts.data.ordered.by.chr <- rbind(counts.data.ordered.by.chr, counts.data[25:26, ], counts.data[23:24, ])
	#cat("For human, the hg38 assembly was used. We estimate the number of rRNA reads as those mapped to chrM plus chrUn_GL000220v1, corresponding to 12S, 16S and 5.8S rRNA. The 'Other' category contains all other chr*_random and chrUn_* available.")
	} else if (genome %in% c("mm38", "mm10")) {
	counts.data[,1] <- sapply(counts.data[,1], function(x) gsub("chr", "", x))
	counts.data.chr.order <- order(as.numeric(counts.data[1:19,1]))
	counts.data.ordered.by.chr <- counts.data[1:19, ][counts.data.chr.order, ]
	counts.data.ordered.by.chr <- rbind(counts.data.ordered.by.chr, counts.data[c(20:23), ])
	#cat("For mouse, the ENSEMBL GRCm38 assmembly available in iGenomes was used.")
	} else if (genome=="rn6") {
	counts.data[,1] <- sapply(counts.data[,1], function(x) gsub("chr", "", x))
	counts.data.chr.order <- order(as.numeric(counts.data[1:20,1]))
	counts.data.ordered.by.chr <- counts.data[1:20, ][counts.data.chr.order, ]
	counts.data.ordered.by.chr <- rbind(counts.data.ordered.by.chr, counts.data[c(22,23,21), ])
	#cat("For rat, the rn6 assembly was used.")
	} else if (genome=="susScr3"){
	counts.data[,1] <- sapply(counts.data[,1], function(x) gsub("chr", "", x))
	counts.data.chr.order <- order(as.numeric(counts.data[1:18,1]))
	counts.data.ordered.by.chr <- counts.data[1:18, ][counts.data.chr.order, ]
	counts.data.ordered.by.chr <- rbind(counts.data.ordered.by.chr, counts.data[c(19:22), ]) # "Error:  chunk 23 (label = count.plot) Error in plot.window(...) : need finite 'ylim' values" means incorrect number of chromosomes listed here
	#cat("For pig, the susScr3 assembly was used.")
	}else if (genome=="Zv9") {
	counts.data <- counts.data[order(counts.data[, 1]), ]
	counts.data.chr.order <- order(as.numeric(levels(counts.data[1:25,1])[as.integer(counts.data[1:25,1])]))
	counts.data.ordered.by.chr <- counts.data[1:25, ][counts.data.chr.order, ]
	counts.data.ordered.by.chr <- rbind(counts.data.ordered.by.chr, counts.data[26:27, ])
	#cat("For zebrafish, the Zv9 assembly comprises a sequence length of 1.4 Gb in 26 chromosomes (labels 1-25 and MT) and 1,107 scaffolds (merged into label 'Other').")
	}
```

```{r, eval=T, echo=F, message=FALSE, fig.width=14, fig.height=10}
par(lwd=20*delta,mai=c(1.02,1,0.82,5))
for (i in c(1:length(sample.names))){
	  sample.index <- i+2
	  if (i==1) {
		 # "plot" function is generating the plot. so why do we have ggplot code below? figure this out
		 plot(counts.data.ordered.by.chr[,sample.index], type="h", col=c[i], xlab="Chromosome", ylab="Read Counts", main=project_name, axes=FALSE, ylim=c(0, max(counts.data.ordered.by.chr[,c(3:length(names(counts.data.ordered.by.chr)))])), cex.axis=1, cex.lab=1, cex.main=2, las=2)
	  	 
			
		 counts.data.melted <- melt(counts.data.ordered.by.chr)
		 counts.data.melted <- counts.data.melted[!(counts.data.melted$variable == "Length"),]
		 #sum.data.melted$which <- factor(sum.data.melted$which, levels=c("mRNA", "Intronic", "Intergenic")) # desired order

	 	 ggplot(data = counts.data.melted, aes(x = Chromosome, y = value, fill=variable)) + 
			geom_bar(stat="identity", position = "dodge") +  #note stacked is default for ggplot2, so must specify "dodge" to get side-by-side bars
			#scale_fill_manual(values=c("red", "darkblue", "darkgreen")) +
			labs(title=project_name, x="Chromosome", y="Read Counts") +
			ylim(0, 100) +
			theme_bw() +
			theme(axis.text.x = element_text(angle = 90, hjust = 1, size=14),
				legend.title = element_text(color="white", size=12),
				legend.text = element_text(size = 16),
		           	axis.text.y = element_text(size=16),
         			plot.title = element_text(size=20, hjust = 0.5, face="bold"),
		           	axis.title.x = element_text(size=18),
         			axis.title.y = element_text(size=18))

	  } else {
		 shifted = c(1:length(counts.data.ordered.by.chr[,1]))+delta*(i-1)
		 lines(shifted, counts.data.ordered.by.chr[,sample.index], type="h", col=c[i])
	  }
}
axis(side=1, labels=counts.data.ordered.by.chr[ ,1], at=c(1:length(counts.data.ordered.by.chr[,1])), cex.axis=1.75, cex.lab=1.75, las=2)
axis(side=2, cex.axis=1.75, cex.lab=2)
legend("right", sample.names, fill=c, bty="n", border=c, cex=1.1, xpd=TRUE, inset=-0.46)
```

### Mapped Reads to Reference Genome

```{r, eval=T, echo=F, message=FALSE}
#Add in the total row at bottom
count.total <- colSums(counts.data.ordered.by.chr[ , c(3:length(names(counts.data.ordered.by.chr))), drop=FALSE])
count.total.table <- counts.data.ordered.by.chr[ , c(3:length(names(counts.data.ordered.by.chr))), drop=FALSE]
count.total.table <- rbind(count.total.table, count.total)
if (class(counts.data.ordered.by.chr[,1]) == "factor") {
	row.names(count.total.table) <- c(levels(counts.data.ordered.by.chr[,1])[as.integer(counts.data.ordered.by.chr[, 1])], "Total")
} else {
	row.names(count.total.table) <- c(counts.data.ordered.by.chr[,1], "Total")
}
#print(xtable(count.total.table, caption="Mapped Reads to Reference Genome", digits=0, align=rep("r", dim(count.total.table)[2]+1)), type="html", label="tab:seven", table.placement="tbp", caption.placement="top")
DT::datatable(count.total.table, options = list(pageLength = 30))
```


### Percent of Total Reads Mapped to Reference Genome
 
```{r, eval=T, echo=F, message=FALSE}
counts.percent.table <- 100*counts.data.ordered.by.chr[ , c(3:length(names(counts.data.ordered.by.chr))), drop=FALSE] / rep(count.total, each=nrow(counts.data.ordered.by.chr[, c(3:length(names(counts.data.ordered.by.chr)))])) 
counts.percent.table <- rbind(counts.percent.table, colSums(counts.percent.table))
if (class(counts.data.ordered.by.chr[,1]) == "factor") {
	row.names(counts.percent.table) <- c(levels(counts.data.ordered.by.chr[,1])[as.integer(counts.data.ordered.by.chr[, 1])], "Total")
} else {
	row.names(counts.percent.table) <- c(counts.data.ordered.by.chr[,1], "Total")
}
#print(xtable(counts.percent.table, caption="Percent of Total Reads Mapped to Reference Genome", digits=2, align=rep("r", dim(counts.percent.table)[2]+1)), type="html", label="tab:eight", table.placement="tbp", caption.placement="top")
counts.percent.table <- round(counts.percent.table, 2)
DT::datatable(counts.percent.table, options = list(pageLength = 30))
```

## ERCC Spike-in Dose Response Plots

For samples that contained External RNA Controls Consortium (ERCC) Spike-Ins, dose response curves (i.e. plots of ERCC transcript FPKM vs. ERCC transcript molecules) were created. Ideally, the slope and R2 would equal 1.0.


```{r erccplot_func, eval=T, echo=F}
erccplot_func=function(conc,count,colname){
  conc=as.numeric(conc[which(count>0)])
  count=as.numeric(count[which(count>0)])
  dat=data.frame(logconc=log2(conc), logcount=log2(count))
  linear.fit <- lm(logcount ~ logconc, data=dat)
  r2 <- summary(linear.fit)$r.squared
  slope <- as.numeric(linear.fit$coefficients[2])
  if (grepl("count_",colname)) {ylab="Count"} else if (grepl("tpm_",colname)) {ylab="TPM"} else if (grepl("fpkm_",colname)) {ylab="FPKM"}
  p=ggplot(data=dat,aes(x=logconc,y=logcount))+geom_point() +
    geom_smooth(method='lm', se=FALSE, color="red") +
    theme_bw() +
    ggtitle(colname) +
    xlab("Expected concentration (log2 scale)")+
    ylab(paste0("Observed ",ylab," (log2 scale)")) +
    theme(plot.title = element_text(hjust = 0.5))
  if (grepl("FPKM|fpkm", colname)) {
    p=p+annotate('text', 7.5, 0, label=paste0("R-sq =", round(r2,3))) +
      annotate('text', 7.5, -1, label=paste0("slope =", round(slope,3)))}
  else if (grepl("Count|count",colname)) {
    p=p+annotate('text', 5, 0, label=paste0("R-sq =", round(r2,3))) +
      annotate('text', 5, -0.8, label=paste0("slope =", round(slope,3)))}
  else if (grepl("TPM|tpm",colname)) {
    p=p+annotate('text', 5, 0, label=paste0("R-sq =", round(r2,3))) +
      annotate('text', 5, -0.8, label=paste0("slope =", round(slope,3)))}
  print(p)
  return(data.frame(r2=r2, slope=slope))
}
```

```{r, ercc_fit, eval=T, echo=F, message=F, results="asis", fig.height=4, fig.width=4} 
if (exists("ercc.mixes")) {
  if ("1" %in% ercc.mixes | "2" %in% ercc.mixes) {
	sample.names <- sample.names.orig
	if (!file.exists(ambion_file)) {stop("ERCC concentration file", ambion_file, " does not exist")}

	# read in ambion file
	ambion=read.table(ambion_file,header=T, as.is=T, sep='\t')
	ambion=ambion[order(ambion$ERCC.ID),c("ERCC.ID","concentration.in.Mix.1..attomoles.ul.")]
	dilution.factor <- 0.02
	
	ercc.fit.table <- data.frame() # ERCC concordance results
	# select mix type
	for (i in c(1:length(sample.names))){
		curr.sample.name <- names(ercc.data)[grepl(sample.names[i],names(ercc.data))]
		curr.ercc.mix <- ercc.mixes[i]
		# choose mix type
		if (curr.ercc.mix=="1") {
			ambion.sub=ambion[order(ambion$ERCC.ID),c("ERCC.ID","concentration.in.Mix.1..attomoles.ul.")]
		} else if (curr.ercc.mix=="2") {
			ambion.sub=ambion[order(ambion$ERCC.ID),c("ERCC.ID","concentration.in.Mix.2..attomoles.ul.")]
		} else {
			next
		}
	 
		names(ambion.sub)=c("ERCC_ID","Concentration")
		ambion.sub$Concentration=ambion.sub$Concentration*dilution.factor

		# combine ambion concentration with read counts
		dat = merge(ambion.sub, ercc.data[,c("Gene",curr.sample.name)],by.x="ERCC_ID",by.y="Gene" )
		curr.res=erccplot_func(conc=dat[,"Concentration"],count=dat[,curr.sample.name],colname=curr.sample.name)
		ercc.fit.table=rbind(ercc.fit.table,data.frame(Sample=sample.names[i],curr.res))
	}
	write.table(ercc.fit.table, file=paste(project_name,"_ercc_fit.txt",sep=""), row.names=F, quote=F, sep="\t")
  }
} else {
	cat("No ERCC Spike-ins used.")
}
```


```{r, ercc_fit_tb, eval=T, echo=F, message=F, results='asis'}
if (exists("ercc.mixes")) {
  if ("1" %in% ercc.mixes | "2" %in% ercc.mixes) {
    try(HTML(print(xtable(ercc.fit.table, caption="ERCC Spike-in Dose Response Fit Details"), type="html", label="tab:nine", table.placement="tbp", caption.placement="top", floating=FALSE))) #added "try()" when doing pig_lung - else was getting thrown out of loop with 'Error: could not find function "HTML"'
    DT::datatable(ercc.fit.table)
  }
}
```


## Principal Component Analysis (PCA) Plot

```{r pca_func, echo=F}
# rlog_func obtains rlog-transformed count matrix using DESeq2
rlog_func <- function(coldata,countdata) {
  library(DESeq2)
  # match colnames in count data to phenotype data
  names(countdata) <- gsub('count_','',names(countdata))
  countdata <- countdata[,c('Gene',as.character(coldata$Sample))]
  row.names(countdata) <- countdata$Gene
  countdata$Gene <- NULL
  #pre-filter low count genes before running the DESeq2 functions. Keep only genes (rows) that have at least 10 reads total.
  # This helps to reduce the memory size of the dds data object, and we increase the speed of the transformation
  keep <- rowSums(countdata)>=10
  countdata <- countdata[keep,]
  # Read in data
  ddsFullCountTable <- DESeqDataSetFromMatrix(countData = countdata, colData = coldata, design=~Status)
  dds <- DESeq(ddsFullCountTable)
  # Transform data using regularized logarithm
  rld<- rlogTransformation(dds, blind=FALSE)
  return(rld)
}

# The pcastat_func function computes principal components
pcastat_func <- function(m, ntop=500) {
  # calculate the variance for each gene
  rv <- rowVars(m)
  # select the ntop genes by variance
  select <- order(rv, decreasing=TRUE)[seq_len(min(ntop, length(rv)))]
  m=m[select,]
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=coldata[,group_var]
  )
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() + theme_bw()
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("Disease", "Treatment", "Tissue", "Donor")
  legends=c("Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(coldata)] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(coldata[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var)+scale_color_hue(name=legend)
    }
  }
  return(plot_list)
}
```


```{r align_pca, eval=T, echo=F, message=F, warning=F}
if (aligner=="star") {
  coldata <- read.table(sample_info_file, sep='\t', header=TRUE)
  countdata <- read.table(count_data_file, sep='\t', header=TRUE, check.names=FALSE)
  rld <- rlog_func(coldata,countdata)
  pca_dat <- assay(rld)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r pca_tb, eval=T, echo=F, message=F, warning=F, results="asis"}
res_pca <- pcastat_func(m=pca_dat)
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

PCA plots are generated using the first two principle components colored by known factors (e.g. treatment/disease conditions, tissue, and donors), visualizing similarities between arrays and these similarities' correlation to batch effects.

```{r pca_plot, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```
